from moviepy.editor import *
from moviepy.video.fx.all import *
import requests
import numpy as np
import os
import time

def summarize_synopsis(synopsis, model, max_words=100):
    return model.summarize_synopsis(synopsis, max_words)

def ease_out_quad(t):
    return 1 - (1 - t) * (1 - t)

def ease_out_cubic(t):
    return 1 - pow(1 - t, 3)

def ease_out_bounce(t):
    n1 = 7.5625
    d1 = 2.75

    if t < 1 / d1:
        return n1 * t * t
    elif t < 2 / d1:
        t -= 1.5 / d1
        return n1 * t * t + 0.75
    elif t < 2.5 / d1:
        t -= 2.25 / d1
        return n1 * t * t + 0.9375
    else:
        t -= 2.625 / d1
        return n1 * t * t + 0.984375

def sliding_effect(clip, duration=1, side='left', easing='quad'):
    w, h = clip.size
    
    # Ch·ªçn easing function
    if easing == 'cubic':
        ease_func = ease_out_cubic
    elif easing == 'bounce':
        ease_func = ease_out_bounce
    else:  # default quad
        ease_func = ease_out_quad
        
    if side == 'left':
        def slide(t):
            if t > duration:
                return ('left', 'center')
            else:
                progress = t/duration
                eased_progress = ease_func(progress)
                return (-w + (w * eased_progress), 'center')
        return clip.set_position(slide)
    return clip

def adjust_fontsize(text, base_size=35):
    """ƒêi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc ch·ªØ d·ª±a tr√™n ƒë·ªô d√†i vƒÉn b·∫£n"""
    length = len(text)
    if length > 500:
        return base_size - 4  # Gi·∫£m m·∫°nh h∆°n cho vƒÉn b·∫£n r·∫•t d√†i
    elif length > 400:
        return base_size - 3.5
    elif length > 300:
        return base_size - 3
    elif length > 200:
        return base_size - 2.5
    elif length > 150:
        return base_size - 2
    elif length > 100:
        return base_size - 1.5
    elif length > 80:
        return base_size - 1
    elif length > 60:
        return base_size - 0.5
    return base_size

def create_analysis_scenes(W, H, image_width, title_width, image_clip, title_clip, analysis_data):
    scenes = []
    
    # ƒêi·ªÅu ch·ªânh c√°c th√¥ng s·ªë chung
    CONTENT_FONT_SIZE = 28
    LINE_SPACING = 1.2  # Gi·∫£m t·ª´ 1.5 xu·ªëng 1.2
    SCENE_DURATION = 8  # TƒÉng t·ª´ 6 l√™n 8 gi√¢y

    # C·∫£nh ƒêi·ªÉm m·∫°nh & ƒêi·ªÉm y·∫øu
    if "strengths_weaknesses" in analysis_data:
        scene_duration = SCENE_DURATION
        intro_duration = 1.5
        
        # Intro
        intro_bg = ColorClip(size=(W, H), color=(30, 30, 40)).set_duration(intro_duration)
        intro_text = TextClip("ƒêI·ªÇM M·∫†NH & ƒêI·ªÇM Y·∫æU",
                            fontsize=60,
                            color='white',
                            font='Arial',
                            align='center')
        intro_text = intro_text.set_position('center').set_duration(intro_duration)
        intro_text = intro_text.fx(vfx.fadein, duration=0.5)
        intro_text = intro_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
        scene_intro = CompositeVideoClip([intro_bg, intro_text])
        
        # Main content
        scene_bg = ColorClip(size=(W, H), color=(30, 30, 40)).set_duration(scene_duration)
        image_clip_scene = sliding_effect(
            image_clip.set_duration(scene_duration),
            duration=1,
            easing='cubic'
        )
        title_clip_scene = title_clip.set_duration(scene_duration).fx(vfx.fadein, duration=1)
        
        strengths = analysis_data["strengths_weaknesses"]["strengths"]
        weaknesses = analysis_data["strengths_weaknesses"]["weaknesses"]
        
        # C·∫≠p nh·∫≠t font size v√† spacing
        TITLE_FONT_SIZE = 55
        HEADING_FONT_SIZE = 35  
        CONTENT_FONT_SIZE = 28
        LINE_SPACING = 1.2
        
        content_text = "üî∏ ƒêI·ªÇM M·∫†NH:\n"  # B·ªè \n th·ª´a
        content_text += "\n".join(f"‚Ä¢ {s}" for s in strengths)  # Gi·∫£m kho·∫£ng c√°ch
        content_text += "\n\nüî∏ ƒêI·ªÇM Y·∫æU:\n"  # B·ªè \n th·ª´a
        content_text += "\n".join(f"‚Ä¢ {w}" for w in weaknesses)
        
        content_fontsize = adjust_fontsize(content_text, base_size=28)
        content_clip = TextClip(
            content_text,
            fontsize=content_fontsize,
            color='white',
            size=(title_width, None),
            method='caption',
            font='Arial',
            align='west',
            interline=LINE_SPACING
        ).set_duration(scene_duration)
        
        content_clip = content_clip.set_position((image_width + 20, 150))
        content_clip = content_clip.fx(vfx.fadein, duration=1)
        
        scene_main = CompositeVideoClip([scene_bg, image_clip_scene, title_clip_scene, content_clip])
        scenes.append(create_crossfade(scene_intro, scene_main, cross_duration=0.5))
    
    # C·∫£nh ƒê·ªëi t∆∞·ª£ng kh√°n gi·∫£
    if "target_audience" in analysis_data:
        scene_duration = SCENE_DURATION
        intro_duration = 1.5
        
        # Intro
        intro_bg = ColorClip(size=(W, H), color=(35, 35, 45)).set_duration(intro_duration)
        intro_text = TextClip("ƒê·ªêI T∆Ø·ª¢NG KH√ÅN GI·∫¢",
                            fontsize=60,
                            color='white',
                            font='Arial',
                            align='center')
        intro_text = intro_text.set_position('center').set_duration(intro_duration)
        intro_text = intro_text.fx(vfx.fadein, duration=0.5)
        intro_text = intro_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
        scene_intro = CompositeVideoClip([intro_bg, intro_text])
        
        # Main content
        scene_bg = ColorClip(size=(W, H), color=(35, 35, 45)).set_duration(scene_duration)
        image_clip_scene = sliding_effect(
            image_clip.set_duration(scene_duration),
            duration=1,
            easing='bounce'
        )
        title_clip_scene = title_clip.set_duration(scene_duration).fx(vfx.fadein, duration=1)
        
        target = analysis_data["target_audience"]
        content_text = "üéØ NH√ìM TU·ªîI:\n"
        content_text += "\n".join(f"‚Ä¢ {age}" for age in target["age_groups"])
        content_text += "\n\nüéØ S·ªû TH√çCH:\n"
        content_text += "\n".join(f"‚Ä¢ {interest}" for interest in target["interests"])
        content_text += f"\n\nüéØ M√î T·∫¢ CHI TI·∫æT:\n{target['description']}"
        
        content_fontsize = adjust_fontsize(content_text, base_size=28)
        content_clip = TextClip(
            content_text,
            fontsize=content_fontsize,
            color='white',
            size=(title_width, None),
            method='caption',
            font='Arial',
            align='west',
            interline=LINE_SPACING
        ).set_duration(scene_duration)
        
        content_clip = content_clip.set_position((image_width + 20, 150))
        content_clip = content_clip.fx(vfx.fadein, duration=1)
        
        scene_main = CompositeVideoClip([scene_bg, image_clip_scene, title_clip_scene, content_clip])
        scenes.append(create_crossfade(scene_intro, scene_main, cross_duration=0.5))
    
    # C·∫£nh Anime t∆∞∆°ng t·ª±
    if "similar_anime" in analysis_data:
        scene_duration = SCENE_DURATION
        intro_duration = 1.5
        
        # Intro
        intro_bg = ColorClip(size=(W, H), color=(40, 40, 50)).set_duration(intro_duration)
        intro_text = TextClip("ANIME T∆Ø∆†NG T·ª∞",
                            fontsize=60,
                            color='white',
                            font='Arial',
                            align='center')
        intro_text = intro_text.set_position('center').set_duration(intro_duration)
        intro_text = intro_text.fx(vfx.fadein, duration=0.5)
        intro_text = intro_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
        scene_intro = CompositeVideoClip([intro_bg, intro_text])
        
        # Main content
        scene_bg = ColorClip(size=(W, H), color=(40, 40, 50)).set_duration(scene_duration)
        image_clip_scene = sliding_effect(
            image_clip.set_duration(scene_duration),
            duration=1,
            easing='cubic'
        )
        title_clip_scene = title_clip.set_duration(scene_duration).fx(vfx.fadein, duration=1)
        
        similar_anime = analysis_data["similar_anime"]
        content_text = "üé¨ ANIME T∆Ø∆†NG T·ª∞:\n\n"
        for anime in similar_anime:
            content_text += f"‚Ä¢ {anime['title']}\n  {anime['comparison']}\n\n"
        
        content_fontsize = adjust_fontsize(content_text, base_size=28)
        content_clip = TextClip(
            content_text,
            fontsize=content_fontsize,
            color='white',
            size=(title_width, None),
            method='caption',
            font='Arial',
            align='west',
            interline=LINE_SPACING
        ).set_duration(scene_duration)
        
        content_clip = content_clip.set_position((image_width + 20, 150))
        content_clip = content_clip.fx(vfx.fadein, duration=1)
        
        scene_main = CompositeVideoClip([scene_bg, image_clip_scene, title_clip_scene, content_clip])
        scenes.append(create_crossfade(scene_intro, scene_main, cross_duration=0.5))
    
    # C·∫£nh ƒê√°nh gi√° t·ªïng quan
    if "overall_rating" in analysis_data:
        scene_duration = SCENE_DURATION
        intro_duration = 1.5
        
        # Intro
        intro_bg = ColorClip(size=(W, H), color=(45, 45, 55)).set_duration(intro_duration)
        intro_text = TextClip("ƒê√ÅNH GI√Å T·ªîNG QUAN",
                            fontsize=60,
                            color='white',
                            font='Arial',
                            align='center')
        intro_text = intro_text.set_position('center').set_duration(intro_duration)
        intro_text = intro_text.fx(vfx.fadein, duration=0.5)
        intro_text = intro_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
        scene_intro = CompositeVideoClip([intro_bg, intro_text])
        
        # Main content
        scene_bg = ColorClip(size=(W, H), color=(45, 45, 55)).set_duration(scene_duration)
        image_clip_scene = sliding_effect(
            image_clip.set_duration(scene_duration),
            duration=1,
            easing='bounce'
        )
        title_clip_scene = title_clip.set_duration(scene_duration).fx(vfx.fadein, duration=1)
        
        rating = analysis_data["overall_rating"]
        content_text = f"‚≠ê ƒêI·ªÇM S·ªê: {rating['score']}/10\n\n"
        content_text += f"üìù NH·∫¨N X√âT:\n{rating['summary']}"
        
        content_fontsize = adjust_fontsize(content_text, base_size=28)
        content_clip = TextClip(
            content_text,
            fontsize=content_fontsize,
            color='white',
            size=(title_width, None),
            method='caption',
            font='Arial',
            align='west',
            interline=LINE_SPACING
        ).set_duration(scene_duration)
        
        content_clip = content_clip.set_position((image_width + 20, 150))
        content_clip = content_clip.fx(vfx.fadein, duration=1)
        
        scene_main = CompositeVideoClip([scene_bg, image_clip_scene, title_clip_scene, content_clip])
        scenes.append(create_crossfade(scene_intro, scene_main, cross_duration=0.5))
    
    return scenes

def get_character_images(anime_id):
    """L·∫•y danh s√°ch ·∫£nh nh√¢n v·∫≠t t·ª´ Jikan API v·ªõi delay"""
    url = f"https://api.jikan.moe/v4/anime/{anime_id}/characters"
    
    # Th√™m delay 2 gi√¢y tr∆∞·ªõc khi g·ªçi API
    time.sleep(2)
    
    try:
        response = requests.get(url)
        
        # Ki·ªÉm tra status code
        if response.status_code == 429:  # Too Many Requests
            print("API rate limit reached. Waiting 5 seconds...")
            time.sleep(5)  # ƒê·ª£i th√™m 5 gi√¢y
            return get_character_images(anime_id)  # Th·ª≠ l·∫°i
            
        data = response.json()
        
        character_images = []
        for char in data.get('data', [])[:6]:  # Gi·ªõi h·∫°n 6 nh√¢n v·∫≠t ch√≠nh
            if char['character']['images']['jpg']['image_url']:
                # Th√™m delay 1 gi√¢y gi·ªØa m·ªói l·∫ßn t·∫£i ·∫£nh
                time.sleep(1)
                
                character_images.append({
                    'name': char['character']['name'],
                    'image_url': char['character']['images']['jpg']['image_url'],
                    'role': char['role']
                })
                
        return character_images
        
    except requests.exceptions.RequestException as e:
        print(f"L·ªói khi l·∫•y th√¥ng tin nh√¢n v·∫≠t: {e}")
        time.sleep(5)  # ƒê·ª£i 5 gi√¢y n·∫øu c√≥ l·ªói
        return []

def create_characters_scene(W, H, image_width, title_width, image_clip, title_clip, characters):
    """T·∫°o c·∫£nh gi·ªõi thi·ªáu nh√¢n v·∫≠t"""
    # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ nh√¢n v·∫≠t n√†o
    if not characters:
        return None
        
    scene_duration = 8
    intro_duration = 1.5
    
    # Intro
    intro_bg = ColorClip(size=(W, H), color=(50, 50, 60)).set_duration(intro_duration)
    intro_text = TextClip("NH√ÇN V·∫¨T CH√çNH",
                         fontsize=60,
                         color='white',
                         font='Arial',
                         align='center')
    intro_text = intro_text.set_position('center').set_duration(intro_duration)
    intro_text = intro_text.fx(vfx.fadein, duration=0.5)
    intro_text = intro_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
    scene_intro = CompositeVideoClip([intro_bg, intro_text])
    
    # Main content
    scene_bg = ColorClip(size=(W, H), color=(50, 50, 60)).set_duration(scene_duration)
    
    # Th√™m image_clip v√† title_clip v√†o c·∫£nh
    image_clip_scene = sliding_effect(
        image_clip.set_duration(scene_duration),
        duration=1,
        easing='cubic'
    )
    title_clip_scene = title_clip.set_duration(scene_duration).fx(vfx.fadein, duration=1)
    
    # ƒêi·ªÅu ch·ªânh v·ªã tr√≠ b·∫Øt ƒë·∫ßu c·ªßa grid nh√¢n v·∫≠t
    y_start = 180  # TƒÉng gi√° tr·ªã n√†y ƒë·ªÉ d√†nh ch·ªó cho title_clip
    
    # T√≠nh to√°n grid d·ª±a tr√™n s·ªë l∆∞·ª£ng nh√¢n v·∫≠t
    num_chars = len(characters)
    if num_chars <= 3:
        grid_width = num_chars
        grid_height = 1
    elif num_chars <= 6:
        grid_width = 3
        grid_height = (num_chars + 2) // 3  # L√†m tr√≤n l√™n
    
    # T√≠nh to√°n k√≠ch th∆∞·ªõc v√† kho·∫£ng c√°ch
    char_width = (title_width) // grid_width
    char_height = (H - 200) // grid_height
    
    # T√≠nh to√°n offset ƒë·ªÉ cƒÉn gi·ªØa grid
    total_width = grid_width * char_width
    x_offset = image_width + (title_width - total_width) // 2 + 20
    
    char_clips = []
    for i, char in enumerate(characters):
        try:
            # Th√™m delay 1 gi√¢y tr∆∞·ªõc m·ªói l·∫ßn t·∫£i ·∫£nh
            time.sleep(1)
            
            response = requests.get(char['image_url'])
            
            # Ki·ªÉm tra status code
            if response.status_code == 429:  # Too Many Requests
                print("API rate limit reached. Waiting 5 seconds...")
                time.sleep(5)
                response = requests.get(char['image_url'])  # Th·ª≠ l·∫°i
                
            temp_path = f"temp_char_{i}.jpg"
            with open(temp_path, "wb") as f:
                f.write(response.content)
                
            char_img = ImageClip(temp_path)
            
            # T√≠nh to√°n k√≠ch th∆∞·ªõc ·∫£nh v·ªõi padding
            target_width = char_width - 40  # padding 20px m·ªói b√™n
            target_height = char_height - 60  # ƒë·ªÉ ch·ª´a ch·ªó cho text
            
            # Resize ·∫£nh gi·ªØ t·ª∑ l·ªá
            img_ratio = char_img.w / char_img.h
            if img_ratio > target_width / target_height:  # ·∫£nh qu√° r·ªông
                char_img = char_img.resize(width=target_width)
                if char_img.h > target_height:
                    char_img = char_img.resize(height=target_height)
            else:  # ·∫£nh qu√° cao
                char_img = char_img.resize(height=target_height)
                if char_img.w > target_width:
                    char_img = char_img.resize(width=target_width)
            
            # T√≠nh to√°n v·ªã tr√≠ trong grid v·ªõi offset
            row = i // grid_width
            col = i % grid_width
            x = x_offset + (col * char_width) + (char_width - char_img.w) // 2  # cƒÉn gi·ªØa theo chi·ªÅu ngang
            y = y_start + (row * char_height) + (target_height - char_img.h) // 2  # cƒÉn gi·ªØa theo chi·ªÅu d·ªçc
            
            char_img = char_img.set_position((x, y))
            char_img = char_img.set_duration(scene_duration)
            char_img = char_img.fx(vfx.fadein, duration=1)
            
            # Th√™m t√™n nh√¢n v·∫≠t
            def translate_role(role):
                roles = {
                    'Main': 'Nh√¢n v·∫≠t ch√≠nh',
                    'Supporting': 'Nh√¢n v·∫≠t ph·ª•',
                    'Background': 'Nh√¢n v·∫≠t n·ªÅn'
                }
                return roles.get(role, role)
            
            name_text = f"{char['name']}\n({translate_role(char['role'])})"
            name_clip = TextClip(name_text,
                               fontsize=20,
                               color='white',
                               size=(char_width-20, None),
                               method='caption',
                               font='Arial',
                               align='center')
            name_y = y + char_img.h + 10
            name_clip = name_clip.set_position((x_offset + (col * char_width) + 10, name_y))
            name_clip = name_clip.set_duration(scene_duration)
            name_clip = name_clip.fx(vfx.fadein, duration=1)
            
            char_clips.extend([char_img, name_clip])
            os.remove(temp_path)
            
        except requests.exceptions.RequestException as e:
            print(f"L·ªói khi t·∫£i ·∫£nh nh√¢n v·∫≠t {char['name']}: {e}")
            continue
    
    # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ clip n√†o ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng
    if not char_clips:
        return None
        
    # T·∫°o composite clip v·ªõi image_clip v√† title_clip
    scene_main = CompositeVideoClip([scene_bg, image_clip_scene, title_clip_scene] + char_clips)
    
    return create_crossfade(scene_intro, scene_main, cross_duration=0.5)

def create_anime_video(anime_info, model):
    # T·∫°o t√™n file an to√†n
    safe_title = sanitize_filename(anime_info['title'])
    output_filename = f"videos/{safe_title}.mp4"
    
    # T·∫£i ·∫£nh t·ª´ URL
    image_url = anime_info['images']['jpg']['large_image_url']
    response = requests.get(image_url)
    with open("temp_image.jpg", "wb") as f:
        f.write(response.content)
    
    # Thi·∫øt l·∫≠p k√≠ch th∆∞·ªõc video v√† background
    W, H = 1280, 720
    background = ColorClip(size=(W, H), color=(0, 0, 0))
    background = background.set_duration(8)
    
    # X·ª≠ l√Ω ·∫£nh (chi·∫øm 40% chi·ªÅu r·ªông m√†n h√¨nh)
    image_width = int(W * 0.4)
    image_clip = ImageClip("temp_image.jpg")
    image_clip = image_clip.resize(width=image_width)
    if image_clip.h > H:
        image_clip = image_clip.resize(height=H)
    image_clip = image_clip.set_position(('left', 'center'))
    image_clip = image_clip.set_duration(8)
    
    # X·ª≠ l√Ω ti√™u ƒë·ªÅ
    title_width = W - image_width - 40
    title_fontsize = 35  # Gi·∫£m k√≠ch th∆∞·ªõc m·∫∑c ƒë·ªãnh xu·ªëng 35

    # ƒêi·ªÅu ch·ªânh c·ª° ch·ªØ d·ª±a tr√™n ƒë·ªô d√†i
    if len(anime_info['title']) > 100:
        title_fontsize = 20
    elif len(anime_info['title']) > 80:
        title_fontsize = 22
    elif len(anime_info['title']) > 60:
        title_fontsize = 25
    elif len(anime_info['title']) > 40:
        title_fontsize = 28
    elif len(anime_info['title']) > 20:
        title_fontsize = 32

    title_clip = TextClip(anime_info['title'], 
                         fontsize=title_fontsize,
                         color='white',
                         size=(title_width, None),
                         method='caption',
                         font='Arial',
                         align='west')
    title_clip = title_clip.set_position((image_width + 20, 50))
    title_clip = title_clip.set_duration(8)
    
    # S·ª≠a ph·∫ßn x·ª≠ l√Ω synopsis
    synopsis_text = model.summarize_synopsis(anime_info['synopsis'])
    if isinstance(synopsis_text, dict) and 'summary' in synopsis_text:
        synopsis_text = synopsis_text['summary']
    
    synopsis_fontsize = adjust_fontsize(synopsis_text, base_size=30)
    synopsis_clip = TextClip(synopsis_text,
                           fontsize=synopsis_fontsize,
                           color='white',
                           size=(title_width, None),
                           method='caption',
                           font='Arial',
                           align='west')
    synopsis_clip = synopsis_clip.set_position((image_width + 20, 150))
    synopsis_clip = synopsis_clip.set_duration(8)
    
    # T·∫°o clip cho c·∫£nh 1 - T√≥m t·∫Øt
    scene1_duration = 8
    scene1_intro_duration = 1.5
    
    # T·∫°o intro cho c·∫£nh 1
    intro1_bg = ColorClip(size=(W, H), color=(0, 0, 0)).set_duration(scene1_intro_duration)
    intro1_text = TextClip("GI·ªöI THI·ªÜU ANIME",
                          fontsize=60,
                          color='white',
                          font='Arial',
                          align='center')
    intro1_text = intro1_text.set_position('center').set_duration(scene1_intro_duration)
    intro1_text = intro1_text.fx(vfx.fadein, duration=0.5)
    intro1_text = intro1_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
    scene1_intro = CompositeVideoClip([intro1_bg, intro1_text])
    
    # T·∫°o n·ªôi dung ch√≠nh c·∫£nh 1
    scene1_bg = ColorClip(size=(W, H), color=(0, 0, 0)).set_duration(scene1_duration)
    image_clip1 = sliding_effect(
        image_clip.set_duration(scene1_duration),
        duration=1.2,
        easing='cubic'
    )
    
    title_clip1 = title_clip.set_duration(scene1_duration)
    title_clip1 = title_clip1.fx(vfx.fadein, duration=1)
    
    synopsis_clip1 = synopsis_clip.set_duration(scene1_duration)
    synopsis_clip1 = synopsis_clip1.fx(vfx.fadein, duration=1.5)
    
    scene1_main = CompositeVideoClip([scene1_bg, image_clip1, title_clip1, synopsis_clip1])
    
    # Th√™m transition gi·ªØa intro v√† main
    scene1 = create_crossfade(scene1_intro, scene1_main, cross_duration=0.5)
    
    # T·∫°o clip cho c·∫£nh 2 - Th√¥ng tin chi ti·∫øt
    scene2_duration = 6
    scene2_intro_duration = 1.5
    
    # T·∫°o intro cho c·∫£nh 2
    intro2_bg = ColorClip(size=(W, H), color=(20, 20, 30)).set_duration(scene2_intro_duration)
    intro2_text = TextClip("TH√îNG TIN CHI TI·∫æT",
                          fontsize=60,
                          color='white',
                          font='Arial',
                          align='center')
    intro2_text = intro2_text.set_position('center').set_duration(scene2_intro_duration)
    intro2_text = intro2_text.fx(vfx.fadein, duration=0.5)
    intro2_text = intro2_text.fx(vfx.resize, lambda t: 1 + 0.1*t)
    scene2_intro = CompositeVideoClip([intro2_bg, intro2_text])
    
    # T·∫°o n·ªôi dung ch√≠nh c·∫£nh 2 v·ªõi layout m·ªõi
    scene2_bg = ColorClip(size=(W, H), color=(20, 20, 30)).set_duration(scene2_duration)
    
    # S·ª≠ d·ª•ng l·∫°i ·∫£nh t·ª´ c·∫£nh 1 cho c·∫£nh 2
    image_clip2 = sliding_effect(
        image_clip.set_duration(scene2_duration),
        duration=1,
        easing='bounce'
    )
    
    title_clip2 = title_clip.set_duration(scene2_duration)
    title_clip2 = title_clip2.fx(vfx.fadein, duration=1)
    
    # T·∫°o text th√¥ng tin chi ti·∫øt
    def translate_status(status):
        statuses = {
            'Finished Airing': 'ƒê√£ ho√†n th√†nh',
            'Currently Airing': 'ƒêang ph√°t s√≥ng',
            'Not yet aired': 'Ch∆∞a ph√°t s√≥ng'
        }
        return statuses.get(status, status)
    
    def translate_duration(duration):
        if 'per ep' in duration.lower():
            return duration.replace('per ep', 'm·ªói t·∫≠p')
        return duration
    
    def translate_aired(aired):
        # Thay th·∫ø c√°c th√°ng ti·∫øng Anh b·∫±ng ti·∫øng Vi·ªát
        months = {
            'Jan': 'Th√°ng 1', 'Feb': 'Th√°ng 2', 'Mar': 'Th√°ng 3',
            'Apr': 'Th√°ng 4', 'May': 'Th√°ng 5', 'Jun': 'Th√°ng 6',
            'Jul': 'Th√°ng 7', 'Aug': 'Th√°ng 8', 'Sep': 'Th√°ng 9',
            'Oct': 'Th√°ng 10', 'Nov': 'Th√°ng 11', 'Dec': 'Th√°ng 12'
        }
        
        for eng, viet in months.items():
            aired = aired.replace(eng, viet)
        return aired.replace('to', 'ƒë·∫øn')
    
    def translate_season(season):
        seasons = {
            'Spring': 'Xu√¢n',
            'Summer': 'H·∫°',
            'Fall': 'Thu',
            'Winter': 'ƒê√¥ng'
        }
        return seasons.get(season, season)
    
    def translate_rating(rating):
        ratings = {
            'G - All Ages': 'M·ªçi l·ª©a tu·ªïi',
            'PG - Children': 'Thi·∫øu nhi',
            'PG-13 - Teens 13 or older': '13 tu·ªïi tr·ªü l√™n',
            'R - 17+ (violence & profanity)': '17 tu·ªïi tr·ªü l√™n (b·∫°o l·ª±c & ng√¥n ng·ªØ)',
            'R+ - Mild Nudity': '17+ (c·∫£nh nh·∫°y c·∫£m)',
            'Rx - Hentai': '18+ (n·ªôi dung ng∆∞·ªùi l·ªõn)'
        }
        return ratings.get(rating, rating)
    
    info_text = f"""
     ƒêi·ªÉm s·ªë: {anime_info.get('score', 'N/A')}
     Th·ªÉ lo·∫°i: {', '.join(genre['name'] for genre in anime_info.get('genres', []))}
     S·ªë t·∫≠p: {anime_info.get('episodes', 'N/A')}
     T√¨nh tr·∫°ng: {translate_status(anime_info.get('status', 'N/A'))}
     Studio: {', '.join(studio['name'] for studio in anime_info.get('studios', []))}
     Th·ªùi l∆∞·ª£ng: {translate_duration(anime_info.get('duration', 'N/A'))}
     Th·ªùi gian ph√°t s√≥ng: {translate_aired(anime_info.get('aired', {}).get('string', 'N/A'))}
     M√πa: {translate_season(anime_info.get('season', 'N/A'))} {anime_info.get('year', '')}
     Ph√¢n lo·∫°i: {translate_rating(anime_info.get('rating', 'N/A'))}
    """
    
    info_fontsize = adjust_fontsize(info_text, base_size=30)
    info_clip = TextClip(
        info_text,
        fontsize=info_fontsize,
        color='white',
        size=(title_width, None),
        method='caption',
        font='Arial',
        align='west'
    ).set_duration(scene2_duration)
    
    # ƒê·∫∑t v·ªã tr√≠ cho info_clip
    info_clip = info_clip.set_position((image_width + 20, 150))
    info_clip = info_clip.fx(vfx.fadein, duration=1)
    
    # T·∫°o composite clip v·ªõi cc th√†nh ph·∫ßn ƒë√£ ƒë∆°n gi·∫£n h√≥a
    scene2_main = CompositeVideoClip([scene2_bg, image_clip2, title_clip2, info_clip])
    
    # Transition gi·ªØa intro v√† main c·∫£nh 2
    scene2 = create_crossfade(scene2_intro, scene2_main, cross_duration=0.5)
    
    # Kh·ªüi t·∫°o danh s√°ch c·∫£nh ph√¢n t√≠ch tr∆∞·ªõc
    analysis_scenes = []
    
    # Th√™m c·∫£nh nh√¢n v·∫≠t
    characters = get_character_images(anime_info['mal_id'])
    if characters:
        characters_scene = create_characters_scene(W, H, image_width, title_width,
                                                image_clip, title_clip, characters)
        if characters_scene:  # Ch·ªâ th√™m c·∫£nh n·∫øu t·∫°o th√†nh c√¥ng
            analysis_scenes.append(characters_scene)
    
    # Th√™m c√°c c·∫£nh ph√¢n t√≠ch kh√°c
    analysis_data = model.analyze_anime(anime_info)
    if analysis_data:
        analysis_scenes.extend(create_analysis_scenes(W, H, image_width, title_width, 
                                                   image_clip, title_clip, analysis_data))
    
    # T·∫°o clip cho c·∫£nh 4 - Call to action
    scene4_duration = 4
    scene4_bg = ColorClip(size=(W, H), color=(40, 40, 50)).set_duration(scene4_duration)
    
    cta_text = """
    üëâ ƒêƒÉng k√Ω k√™nh ƒë·ªÉ xem th√™m anime hay!
    üîî B·∫≠t th√¥ng b√°o ƒë·ªÉ kh√¥ng b·ªè l·ª° video m·ªõi nh·∫•t
    """
    
    cta_text = TextClip(cta_text,
                       fontsize=40,
                       color='white',
                       size=(W-100, None),
                       method='caption',
                       font='Arial',
                       align='center')
    cta_text = cta_text.set_position(('center', 'center'))
    cta_text = cta_text.set_duration(scene4_duration)
    
    # Animation cho Call to Action
    def cta_scale(t):
        # T·∫°o hi·ªáu ·ª©ng pulse m∆∞·ª£t m√† h∆°n v·ªõi easing
        scale = 1 + 0.05 * np.sin(2 * np.pi * t)
        return ease_out_quad(scale)
    
    cta_text = cta_text.fx(vfx.resize, cta_scale)
    
    scene4 = CompositeVideoClip([scene4_bg, cta_text])
    
    # Gh√©p t·∫•t c·∫£ c√°c c·∫£nh l·∫°i v·ªõi nhau
    def concatenate_with_crossfade(clips, cross_duration=0.7):
        final_clips = [clips[0]]
        for i in range(1, len(clips)):
            clip = clips[i].set_start(sum(c.duration for c in clips[:i]) - cross_duration)
            clip = clip.crossfadein(cross_duration)
            final_clips.append(clip)
        return CompositeVideoClip(final_clips)

    # C·∫≠p nh·∫≠t ph·∫ßn gh√©p c·∫£nh
    final_clip = concatenate_with_crossfade([scene1, scene2] + analysis_scenes + [scene4], cross_duration=0.7)
    
    # Xu·∫•t video
    final_clip.write_videofile(output_filename,
                             fps=24,
                             codec='libx264')
    return output_filename

def sanitize_filename(filename):
    invalid_chars = '<>:"/\\|?*'
    for char in invalid_chars:
        filename = filename.replace(char, '')
    return filename.strip()

# C·∫£nh 1
def create_crossfade(clip1, clip2, cross_duration=0.5):
    clip2 = clip2.set_start(clip1.duration - cross_duration)
    clip2 = clip2.crossfadein(cross_duration)
    return CompositeVideoClip([clip1, clip2])

# Th√™m c√°c h√†m d·ªãch m·ªõi
def translate_status(status):
    statuses = {
        'Finished Airing': 'ƒê√£ ho√†n th√†nh',
        'Currently Airing': 'ƒêang ph√°t s√≥ng',
        'Not yet aired': 'Ch∆∞a ph√°t s√≥ng'
    }
    return statuses.get(status, status)

def translate_duration(duration):
    if 'per ep' in duration.lower():
        return duration.replace('per ep', 'm·ªói t·∫≠p')
    return duration

def translate_aired(aired):
    # Thay th·∫ø c√°c th√°ng ti·∫øng Anh b·∫±ng ti·∫øng Vi·ªát
    months = {
        'Jan': 'Th√°ng 1', 'Feb': 'Th√°ng 2', 'Mar': 'Th√°ng 3',
        'Apr': 'Th√°ng 4', 'May': 'Th√°ng 5', 'Jun': 'Th√°ng 6',
        'Jul': 'Th√°ng 7', 'Aug': 'Th√°ng 8', 'Sep': 'Th√°ng 9',
        'Oct': 'Th√°ng 10', 'Nov': 'Th√°ng 11', 'Dec': 'Th√°ng 12'
    }
    
    for eng, viet in months.items():
        aired = aired.replace(eng, viet)
    return aired.replace('to', 'ƒë·∫øn')

def translate_season(season):
    seasons = {
        'Spring': 'Xu√¢n',
        'Summer': 'H·∫°',
        'Fall': 'Thu',
        'Winter': 'ƒê√¥ng'
    }
    return seasons.get(season, season)

def translate_rating(rating):
    ratings = {
        'G - All Ages': 'M·ªçi l·ª©a tu·ªïi',
        'PG - Children': 'Thi·∫øu nhi',
        'PG-13 - Teens 13 or older': '13 tu·ªïi tr·ªü l√™n',
        'R - 17+ (violence & profanity)': '17 tu·ªïi tr·ªü l√™n (b·∫°o l·ª±c & ng√¥n ng·ªØ)',
        'R+ - Mild Nudity': '17+ (c·∫£nh nh·∫°y c·∫£m)',
        'Rx - Hentai': '18+ (n·ªôi dung ng∆∞·ªùi l·ªõn)'
    }
    return ratings.get(rating, rating)